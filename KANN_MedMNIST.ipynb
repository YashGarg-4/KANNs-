{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2k5c-qrYMq5P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "\n",
        "class KANLinear(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        enable_standalone_scale_spline=True,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KANLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = (\n",
        "            (\n",
        "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
        "                + grid_range[0]\n",
        "            )\n",
        "            .expand(in_features, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "\n",
        "        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.spline_weight = torch.nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
        "        )\n",
        "        if enable_standalone_scale_spline:\n",
        "            self.spline_scaler = torch.nn.Parameter(\n",
        "                torch.Tensor(out_features, in_features)\n",
        "            )\n",
        "\n",
        "        self.scale_noise = scale_noise\n",
        "        self.scale_base = scale_base\n",
        "        self.scale_spline = scale_spline\n",
        "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
        "        self.base_activation = base_activation()\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
        "        with torch.no_grad():\n",
        "            noise = (\n",
        "                (\n",
        "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
        "                    - 1 / 2\n",
        "                )\n",
        "                * self.scale_noise\n",
        "                / self.grid_size\n",
        "            )\n",
        "            self.spline_weight.data.copy_(\n",
        "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
        "                * self.curve2coeff(\n",
        "                    self.grid.T[self.spline_order : -self.spline_order],\n",
        "                    noise,\n",
        "                )\n",
        "            )\n",
        "            if self.enable_standalone_scale_spline:\n",
        "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
        "                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
        "\n",
        "    def b_splines(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the B-spline bases for the given input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        grid: torch.Tensor = (\n",
        "            self.grid\n",
        "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = (\n",
        "                (x - grid[:, : -(k + 1)])\n",
        "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (grid[:, k + 1 :] - x)\n",
        "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "\n",
        "        assert bases.size() == (\n",
        "            x.size(0),\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return bases.contiguous()\n",
        "\n",
        "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the coefficients of the curve that interpolates the given points.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
        "\n",
        "        A = self.b_splines(x).transpose(\n",
        "            0, 1\n",
        "        )  # (in_features, batch_size, grid_size + spline_order)\n",
        "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
        "        solution = torch.linalg.lstsq(\n",
        "            A, B\n",
        "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
        "        result = solution.permute(\n",
        "            2, 0, 1\n",
        "        )  # (out_features, in_features, grid_size + spline_order)\n",
        "\n",
        "        assert result.size() == (\n",
        "            self.out_features,\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return result.contiguous()\n",
        "\n",
        "    @property\n",
        "    def scaled_spline_weight(self):\n",
        "        return self.spline_weight * (\n",
        "            self.spline_scaler.unsqueeze(-1)\n",
        "            if self.enable_standalone_scale_spline\n",
        "            else 1.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "        spline_output = F.linear(\n",
        "            self.b_splines(x).view(x.size(0), -1),\n",
        "            self.scaled_spline_weight.view(self.out_features, -1),\n",
        "        )\n",
        "        return base_output + spline_output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        batch = x.size(0)\n",
        "\n",
        "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
        "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
        "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
        "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
        "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
        "        unreduced_spline_output = unreduced_spline_output.permute(\n",
        "            1, 0, 2\n",
        "        )  # (batch, in, out)\n",
        "\n",
        "        # sort each channel individually to collect data distribution\n",
        "        x_sorted = torch.sort(x, dim=0)[0]\n",
        "        grid_adaptive = x_sorted[\n",
        "            torch.linspace(\n",
        "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
        "        grid_uniform = (\n",
        "            torch.arange(\n",
        "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
        "            ).unsqueeze(1)\n",
        "            * uniform_step\n",
        "            + x_sorted[0]\n",
        "            - margin\n",
        "        )\n",
        "\n",
        "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
        "        grid = torch.concatenate(\n",
        "            [\n",
        "                grid[:1]\n",
        "                - uniform_step\n",
        "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
        "                grid,\n",
        "                grid[-1:]\n",
        "                + uniform_step\n",
        "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.grid.copy_(grid.T)\n",
        "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        \"\"\"\n",
        "        Compute the regularization loss.\n",
        "\n",
        "        This is a dumb simulation of the original L1 regularization as stated in the\n",
        "        paper, since the original one requires computing absolutes and entropy from the\n",
        "        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n",
        "        behind the F.linear function if we want an memory efficient implementation.\n",
        "\n",
        "        The L1 regularization is now computed as mean absolute value of the spline\n",
        "        weights. The authors implementation also includes this term in addition to the\n",
        "        sample-based regularization.\n",
        "        \"\"\"\n",
        "        l1_fake = self.spline_weight.abs().mean(-1)\n",
        "        regularization_loss_activation = l1_fake.sum()\n",
        "        p = l1_fake / regularization_loss_activation\n",
        "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
        "        return (\n",
        "            regularize_activation * regularization_loss_activation\n",
        "            + regularize_entropy * regularization_loss_entropy\n",
        "        )\n",
        "\n",
        "\n",
        "class KAN(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers_hidden,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KAN, self).__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
        "            self.layers.append(\n",
        "                KANLinear(\n",
        "                    in_features,\n",
        "                    out_features,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, update_grid=False):\n",
        "        for layer in self.layers:\n",
        "            if update_grid:\n",
        "                layer.update_grid(x)\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        return sum(\n",
        "            layer.regularization_loss(regularize_activation, regularize_entropy)\n",
        "            for layer in self.layers\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsZVajXNk83M",
        "outputId": "bb3a51c1-4c08-4bde-9b0c-61177e55667f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsummary\n",
            "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
            "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
            "Installing collected packages: torchsummary\n",
            "Successfully installed torchsummary-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "\n",
        "# KANLinear definition Soure: https://github.com/Blealtan/efficient-kan/blob/f39e5146af34299ad3a581d2106eb667ba0fa6fa/src/efficient_kan/kan.py#L6\n",
        "class KANLinear(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        enable_standalone_scale_spline=True,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KANLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = (\n",
        "            (\n",
        "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
        "                + grid_range[0]\n",
        "            )\n",
        "            .expand(in_features, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "\n",
        "        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.spline_weight = torch.nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
        "        )\n",
        "        if enable_standalone_scale_spline:\n",
        "            self.spline_scaler = torch.nn.Parameter(\n",
        "                torch.Tensor(out_features, in_features)\n",
        "            )\n",
        "\n",
        "        self.scale_noise = scale_noise\n",
        "        self.scale_base = scale_base\n",
        "        self.scale_spline = scale_spline\n",
        "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
        "        self.base_activation = base_activation()\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
        "        with torch.no_grad():\n",
        "            noise = (\n",
        "                (\n",
        "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
        "                    - 1 / 2\n",
        "                )\n",
        "                * self.scale_noise\n",
        "                / self.grid_size\n",
        "            )\n",
        "            self.spline_weight.data.copy_(\n",
        "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
        "                * self.curve2coeff(\n",
        "                    self.grid.T[self.spline_order : -self.spline_order],\n",
        "                    noise,\n",
        "                )\n",
        "            )\n",
        "            if self.enable_standalone_scale_spline:\n",
        "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
        "                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
        "\n",
        "    def b_splines(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the B-spline bases for the given input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        grid: torch.Tensor = (\n",
        "            self.grid\n",
        "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = (\n",
        "                (x - grid[:, : -(k + 1)])\n",
        "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (grid[:, k + 1 :] - x)\n",
        "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "\n",
        "        assert bases.size() == (\n",
        "            x.size(0),\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return bases.contiguous()\n",
        "\n",
        "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the coefficients of the curve that interpolates the given points.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
        "\n",
        "        A = self.b_splines(x).transpose(\n",
        "            0, 1\n",
        "        )  # (in_features, batch_size, grid_size + spline_order)\n",
        "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
        "        solution = torch.linalg.lstsq(\n",
        "            A, B\n",
        "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
        "        result = solution.permute(\n",
        "            2, 0, 1\n",
        "        )  # (out_features, in_features, grid_size + spline_order)\n",
        "\n",
        "        assert result.size() == (\n",
        "            self.out_features,\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return result.contiguous()\n",
        "\n",
        "    @property\n",
        "    def scaled_spline_weight(self):\n",
        "        return self.spline_weight * (\n",
        "            self.spline_scaler.unsqueeze(-1)\n",
        "            if self.enable_standalone_scale_spline\n",
        "            else 1.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "        spline_output = F.linear(\n",
        "            self.b_splines(x).view(x.size(0), -1),\n",
        "            self.scaled_spline_weight.view(self.out_features, -1),\n",
        "        )\n",
        "        return base_output + spline_output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        batch = x.size(0)\n",
        "\n",
        "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
        "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
        "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
        "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
        "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
        "        unreduced_spline_output = unreduced_spline_output.permute(\n",
        "            1, 0, 2\n",
        "        )  # (batch, in, out)\n",
        "\n",
        "        # sort each channel individually to collect data distribution\n",
        "        x_sorted = torch.sort(x, dim=0)[0]\n",
        "        grid_adaptive = x_sorted[\n",
        "            torch.linspace(\n",
        "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
        "        grid_uniform = (\n",
        "            torch.arange(\n",
        "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
        "            ).unsqueeze(1)\n",
        "            * uniform_step\n",
        "            + x_sorted[0]\n",
        "            - margin\n",
        "        )\n",
        "\n",
        "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
        "        grid = torch.concatenate(\n",
        "            [\n",
        "                grid[:1]\n",
        "                - uniform_step\n",
        "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
        "                grid,\n",
        "                grid[-1:]\n",
        "                + uniform_step\n",
        "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.grid.copy_(grid.T)\n",
        "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        \"\"\"\n",
        "        Compute the regularization loss.\n",
        "\n",
        "        This is a dumb simulation of the original L1 regularization as stated in the\n",
        "        paper, since the original one requires computing absolutes and entropy from the\n",
        "        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n",
        "        behind the F.linear function if we want an memory efficient implementation.\n",
        "\n",
        "        The L1 regularization is now computed as mean absolute value of the spline\n",
        "        weights. The authors implementation also includes this term in addition to the\n",
        "        sample-based regularization.\n",
        "        \"\"\"\n",
        "        l1_fake = self.spline_weight.abs().mean(-1)\n",
        "        regularization_loss_activation = l1_fake.sum()\n",
        "        p = l1_fake / regularization_loss_activation\n",
        "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
        "        return (\n",
        "            regularize_activation * regularization_loss_activation\n",
        "            + regularize_entropy * regularization_loss_entropy\n",
        "        )\n",
        "\n",
        "# CNN model for CIFAR-10 with KANLinear\n",
        "class CNNKAN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNKAN, self).__init__()\n",
        "    #     self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "    #     self.pool1 = nn.MaxPool2d(2)\n",
        "    #     self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "    #     self.pool2 = nn.MaxPool2d(2)\n",
        "    #     self.kan1 = KANLinear(64 * 8 * 8, 256)\n",
        "    #     self.kan2 = KANLinear(256, 9)\n",
        "\n",
        "    # def forward(self, x):\n",
        "    #     x = F.selu(self.conv1(x))\n",
        "    #     x = self.pool1(x)\n",
        "    #     x = F.selu(self.conv2(x))\n",
        "    #     x = self.pool2(x)\n",
        "    #     x = x.view(x.size(0), -1)\n",
        "    #     x = self.kan1(x)\n",
        "    #     x = self.kan2(x)\n",
        "    #     return x\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, kernel_size=3),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            KANLinear(64 * 4 * 4, 128),\n",
        "            nn.ReLU(),\n",
        "            KANLinear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            KANLinear(128, 9))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "def print_parameter_details(model):\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if parameter.requires_grad:\n",
        "            params = parameter.numel()  # Number of elements in the tensor\n",
        "            total_params += params\n",
        "            print(f\"{name}: {params}\")\n",
        "    print(f\"Total trainable parameters: {total_params}\")\n",
        "\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Uncommnet this line for CNN KAN.\n",
        "model = CNNKAN().to(device)\n",
        "print(model)\n",
        "print_parameter_details(model)\n",
        "# summary(model,  input_size=(3, 32, 32))\n",
        "\n",
        "# Note the this is just a rough demo for Visualization. Need modifcation.\n",
        "def visualize_kan_parameters(kan_layer, layer_name):\n",
        "    base_weights = kan_layer.base_weight.data.cpu().numpy()\n",
        "    plt.hist(base_weights.ravel(), bins=50)\n",
        "    plt.title(f\"Distribution of Base Weights - {layer_name}\")\n",
        "    plt.xlabel(\"Weight Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "    if hasattr(kan_layer, 'spline_weight'):\n",
        "        spline_weights = kan_layer.spline_weight.data.cpu().numpy()\n",
        "        plt.hist(spline_weights.ravel(), bins=50)\n",
        "        plt.title(f\"Distribution of Spline Weights - {layer_name}\")\n",
        "        plt.xlabel(\"Weight Value\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.show()\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.size()} {'requires_grad' if param.requires_grad else 'frozen'}\")\n",
        "\n",
        "# TODO: Need to explore various Optimizer and optimize the Learning Rate.\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvlvq636Mue8",
        "outputId": "515cf62b-a4d0-4b39-9f2a-1c2c52578b1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNKAN(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (layer5): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): KANLinear(\n",
            "      (base_activation): SiLU()\n",
            "    )\n",
            "    (1): ReLU()\n",
            "    (2): KANLinear(\n",
            "      (base_activation): SiLU()\n",
            "    )\n",
            "    (3): ReLU()\n",
            "    (4): KANLinear(\n",
            "      (base_activation): SiLU()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "layer1.0.weight: 144\n",
            "layer1.0.bias: 16\n",
            "layer1.1.weight: 16\n",
            "layer1.1.bias: 16\n",
            "layer2.0.weight: 2304\n",
            "layer2.0.bias: 16\n",
            "layer2.1.weight: 16\n",
            "layer2.1.bias: 16\n",
            "layer3.0.weight: 9216\n",
            "layer3.0.bias: 64\n",
            "layer3.1.weight: 64\n",
            "layer3.1.bias: 64\n",
            "layer4.0.weight: 36864\n",
            "layer4.0.bias: 64\n",
            "layer4.1.weight: 64\n",
            "layer4.1.bias: 64\n",
            "layer5.0.weight: 36864\n",
            "layer5.0.bias: 64\n",
            "layer5.1.weight: 64\n",
            "layer5.1.bias: 64\n",
            "fc.0.base_weight: 131072\n",
            "fc.0.spline_weight: 1048576\n",
            "fc.0.spline_scaler: 131072\n",
            "fc.2.base_weight: 16384\n",
            "fc.2.spline_weight: 131072\n",
            "fc.2.spline_scaler: 16384\n",
            "fc.4.base_weight: 1152\n",
            "fc.4.spline_weight: 9216\n",
            "fc.4.spline_scaler: 1152\n",
            "Total trainable parameters: 1572144\n",
            "layer1.0.weight: torch.Size([16, 1, 3, 3]) requires_grad\n",
            "layer1.0.bias: torch.Size([16]) requires_grad\n",
            "layer1.1.weight: torch.Size([16]) requires_grad\n",
            "layer1.1.bias: torch.Size([16]) requires_grad\n",
            "layer2.0.weight: torch.Size([16, 16, 3, 3]) requires_grad\n",
            "layer2.0.bias: torch.Size([16]) requires_grad\n",
            "layer2.1.weight: torch.Size([16]) requires_grad\n",
            "layer2.1.bias: torch.Size([16]) requires_grad\n",
            "layer3.0.weight: torch.Size([64, 16, 3, 3]) requires_grad\n",
            "layer3.0.bias: torch.Size([64]) requires_grad\n",
            "layer3.1.weight: torch.Size([64]) requires_grad\n",
            "layer3.1.bias: torch.Size([64]) requires_grad\n",
            "layer4.0.weight: torch.Size([64, 64, 3, 3]) requires_grad\n",
            "layer4.0.bias: torch.Size([64]) requires_grad\n",
            "layer4.1.weight: torch.Size([64]) requires_grad\n",
            "layer4.1.bias: torch.Size([64]) requires_grad\n",
            "layer5.0.weight: torch.Size([64, 64, 3, 3]) requires_grad\n",
            "layer5.0.bias: torch.Size([64]) requires_grad\n",
            "layer5.1.weight: torch.Size([64]) requires_grad\n",
            "layer5.1.bias: torch.Size([64]) requires_grad\n",
            "fc.0.base_weight: torch.Size([128, 1024]) requires_grad\n",
            "fc.0.spline_weight: torch.Size([128, 1024, 8]) requires_grad\n",
            "fc.0.spline_scaler: torch.Size([128, 1024]) requires_grad\n",
            "fc.2.base_weight: torch.Size([128, 128]) requires_grad\n",
            "fc.2.spline_weight: torch.Size([128, 128, 8]) requires_grad\n",
            "fc.2.spline_scaler: torch.Size([128, 128]) requires_grad\n",
            "fc.4.base_weight: torch.Size([9, 128]) requires_grad\n",
            "fc.4.spline_weight: torch.Size([9, 128, 8]) requires_grad\n",
            "fc.4.spline_scaler: torch.Size([9, 128]) requires_grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5D8uF67OU52",
        "outputId": "9978a3a6-d438-4674-82ca-cb9a0188eee3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.24.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (11.0.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.5.1+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.20.1+cpu)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=13edbcf1817b2eebee5c62078e993cf5cd805db7d40233676e3858758249746b\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.0 medmnist-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "OuQydINzVdi9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jL5SwORZv8P",
        "outputId": "0cc84e69-8311-48ab-b8a7-e744e32238d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedMNIST v3.0.2 @ https://github.com/MedMNIST/MedMNIST/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'pathmnist'\n",
        "# data_flag = 'breastmnist'\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 128\n",
        "lr = 0.001\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "# n_channels = info['n_channels']\n",
        "# n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])"
      ],
      "metadata": {
        "id": "ch72w0plZwvW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convert RGB to grayscale\n",
        "    transforms.Resize((28, 28)),  # Ensure the size is still 28x28\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] for grayscale\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
        "\n",
        "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
        "\n",
        "pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OklNwa1hZ0rm",
        "outputId": "ec328dae-4adb-46ae-8948-d01909f43104"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /root/.medmnist/pathmnist.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 206M/206M [00:08<00:00, 23.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/pathmnist.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "wZ6NZwKphaLc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbt3sTYWgg9E",
        "outputId": "923aaa5c-997e-4105-d999-4712386c3cde"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 704/704 [00:51<00:00, 13.60it/s]\n",
            "100%|██████████| 704/704 [00:49<00:00, 14.21it/s]\n",
            "100%|██████████| 704/704 [00:50<00:00, 13.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([])\n",
        "    y_score = torch.tensor([])\n",
        "\n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.numpy()\n",
        "        y_score = y_score.detach().numpy()\n",
        "\n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "\n",
        "\n",
        "print('==> Evaluating ...')\n",
        "test('train')\n",
        "test('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6reuu9Shv2v",
        "outputId": "972cac61-fe3c-43e4-e0f6-fb411f1bd1d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Evaluating ...\n",
            "train  auc: 0.970  acc:0.761\n",
            "test  auc: 0.957  acc:0.713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train ##2\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # train_correct = 0\n",
        "    # train_total = 0\n",
        "    # test_correct = 0\n",
        "    # test_total = 0\n",
        "\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qrbFMK3lP3P",
        "outputId": "b236320b-ff44-433f-dbce-ec3b7d18fa30"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 704/704 [00:51<00:00, 13.76it/s]\n",
            "100%|██████████| 704/704 [00:50<00:00, 14.00it/s]\n",
            "100%|██████████| 704/704 [00:49<00:00, 14.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation ##2\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([])\n",
        "    y_score = torch.tensor([])\n",
        "\n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.numpy()\n",
        "        y_score = y_score.detach().numpy()\n",
        "\n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "\n",
        "\n",
        "print('==> Evaluating ...')\n",
        "test('train')\n",
        "test('test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU8Ybu3BlQrW",
        "outputId": "c016c7b5-fa1b-4bfd-ad8a-8af2eb636da6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Evaluating ...\n",
            "train  auc: 0.989  acc:0.872\n",
            "test  auc: 0.976  acc:0.812\n"
          ]
        }
      ]
    }
  ]
}